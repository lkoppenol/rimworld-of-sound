{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "allied-advancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from loguru import logger\n",
    "import librosa\n",
    "import librosa.display\n",
    "from librosa import mel_frequencies\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.io import FixedLenFeature, parse_single_example\n",
    "\n",
    "from pathlib2 import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntProgress\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spiritual-museum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Projects/rimworld-of-sound/data')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../data/\").resolve()\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dangerous-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HParams(object):\n",
    "    \"\"\" Hparams was removed from tf 2.0alpha so this is a placeholder\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "hparams = HParams( \n",
    "    # network\n",
    "    batch_size = 32,\n",
    "    # spectrogramming\n",
    "    sample_rate = 16000,\n",
    "    create_spectrogram = True,\n",
    "    win_length = 1024,\n",
    "    n_fft = 1024,\n",
    "    hop_length= 400,\n",
    "    ref_level_db = 50,\n",
    "    min_level_db = -100,\n",
    "    # mel scaling\n",
    "    num_mel_bins = 128,\n",
    "    mel_lower_edge_hertz = 0,\n",
    "    mel_upper_edge_hertz = 8000,\n",
    "    # inversion\n",
    "    power = 1.5, # for spectral inversion\n",
    "    griffin_lim_iters = 50,\n",
    "    pad=True,\n",
    "    #\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "enclosed-demonstration",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Feature: id (data type: string) is required but could not be found. [Op:ParseExampleV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-547145a51d41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mraw_record\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_single_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_record\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_stft_tensorflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"audio\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\u001b[0m in \u001b[0;36mparse_single_example_v2\u001b[1;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[0mserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"serialized\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[0mserialized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_assert_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"serialized\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparse_example_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_v2\u001b[1;34m(serialized, features, example_names, name)\u001b[0m\n\u001b[0;32m    312\u001b[0m   ])\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parse_example_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_construct_tensors_for_composite_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\ops\\parsing_ops.py\u001b[0m in \u001b[0;36m_parse_example_raw\u001b[1;34m(serialized, names, params, name)\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mragged_split_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mragged_split_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[0mdense_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_shapes_as_proto\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m    363\u001b[0m     (sparse_indices, sparse_values, sparse_shapes, dense_values,\n\u001b[0;32m    364\u001b[0m      ragged_values, ragged_row_splits) = outputs\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\ops\\gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_v2\u001b[1;34m(serialized, names, sparse_keys, dense_keys, ragged_keys, dense_defaults, num_sparse, sparse_types, ragged_value_types, ragged_split_types, dense_shapes, name)\u001b[0m\n\u001b[0;32m    737\u001b[0m           \u001b[0mragged_value_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mragged_value_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m           \u001b[0mragged_split_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mragged_split_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdense_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m           name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m    740\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m       \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\ops\\gen_parsing_ops.py\u001b[0m in \u001b[0;36mparse_example_v2_eager_fallback\u001b[1;34m(serialized, names, sparse_keys, dense_keys, ragged_keys, dense_defaults, num_sparse, sparse_types, ragged_value_types, ragged_split_types, dense_shapes, name, ctx)\u001b[0m\n\u001b[0;32m    830\u001b[0m                              \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mragged_value_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m                              \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mragged_split_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_inputs_flat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m    833\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m     _execute.record_gradient(\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Feature: id (data type: string) is required but could not be found. [Op:ParseExampleV2]"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "audio_length = 64_000\n",
    "\n",
    "features = {\n",
    "    \"id\": FixedLenFeature([], dtype=tf.string),\n",
    "    \"pitch\": FixedLenFeature([1], dtype=tf.int64),\n",
    "    \"velocity\": FixedLenFeature([1], dtype=tf.int64),\n",
    "    \"audio\": FixedLenFeature([64000], dtype=tf.float32),\n",
    "    \"instrument/source\": FixedLenFeature([1], dtype=tf.int64),\n",
    "    \"instrument/family\": FixedLenFeature([1], dtype=tf.int64),\n",
    "    \"instrument/label\": FixedLenFeature([1], dtype=tf.int64),\n",
    "}\n",
    "DATA_PATH_VALID = '../data/nsynth-valid.tfrecord'\n",
    "ds_train = tf.data.TFRecordDataset(DATA_PATH_VALID)\\\n",
    "#     .map(_parse_function) \\\n",
    "#     .batch(batch_size)\n",
    "DATA_PATH_TEST = '../data/nsynth-test.tfrecord'\n",
    "ds_test = tf.data.TFRecordDataset(DATA_PATH_TEST)\\\n",
    "#     .map(_parse_function) \\\n",
    "#     .batch(batch_size)\n",
    "\n",
    "def _stft_tensorflow(signals, hparams):\n",
    "    return tf.signal.stft(\n",
    "        signals,\n",
    "        hparams.win_length,\n",
    "        hparams.hop_length,\n",
    "        hparams.n_fft,\n",
    "        pad_end=True,\n",
    "        window_fn=tf.signal.hann_window,\n",
    "    )\n",
    "\n",
    "for raw_record in ds_test.take(1):\n",
    "    example = tf.io.parse_single_example(raw_record, features)\n",
    "    print(_stft_tensorflow(example[\"audio\"], hparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "palestinian-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_train, ds_test = tfds.load(\n",
    "#     name=\"nsynth\", split=[\"valid\", \"test\"], data_dir=DATA_DIR\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sudden-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_tensorflow(S, hparams):\n",
    "    return tf.clip_by_value((S - hparams.min_level_db) / -hparams.min_level_db, 0, 1)\n",
    "\n",
    "def _tf_log10(x):\n",
    "    numerator = tf.math.log(x)\n",
    "    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def _amp_to_db_tensorflow(x):\n",
    "    return 20 * _tf_log10(tf.clip_by_value(tf.abs(x), 1e-5, 1e100))\n",
    "\n",
    "\n",
    "def _stft_tensorflow(signals, hparams):\n",
    "    return tf.signal.stft(\n",
    "        signals,\n",
    "        hparams.win_length,\n",
    "        hparams.hop_length,\n",
    "        hparams.n_fft,\n",
    "        pad_end=True,\n",
    "        window_fn=tf.signal.hann_window,\n",
    "    )\n",
    "\n",
    "\n",
    "def spectrogram_tensorflow(y, hparams):\n",
    "    D = _stft_tensorflow(y, hparams)\n",
    "    S = _amp_to_db_tensorflow(tf.abs(D)) - hparams.ref_level_db\n",
    "    return _normalize_tensorflow(S, hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "domestic-shooting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-color",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-bunch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "going-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_hot(tensor: tf.Tensor, size) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    One hot encode a tensor and return it as 1D tensor\n",
    "    :param tensor:\n",
    "    :param size: number of unique values in tensor\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    hot_tensor = tf.one_hot(tensor, size)\n",
    "    shaped_tensor = tf.reshape(hot_tensor, (size,))\n",
    "    return shaped_tensor\n",
    "\n",
    "def _stft(tensor: tf.Tensor, audio_length, frame_length=255, frame_step=128) -> tf.Tensor:\n",
    "\n",
    "    # Concatenate audio with padding so that all audio clips will be of the \n",
    "    # same length\n",
    "\n",
    "    return tf.abs(tf.signal.stft(tensor, frame_length, frame_step))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "departmental-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def _parse_function(example_proto):\n",
    "    # Schema\n",
    "    audio_length=64_000\n",
    "    features = {\n",
    "        \"pitch\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "        \"audio\": tf.io.FixedLenFeature([audio_length], dtype=tf.float32),\n",
    "        \"velocity\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "        \"instrument_family\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, features)\n",
    "    data = _stft(example['audio'], audio_length)\n",
    "    label_name = 'instrument_family'\n",
    "    label_value_count = 11 #instrument family has 11 types 0,1,2,3,...10\n",
    "    #label_value_count = 128\n",
    "    # label_name = 'velocity'\n",
    "    # label_value_count = 4\n",
    "    label = _one_hot(example[label_name], label_value_count)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "later-nothing",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, int found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-b0860c81d969>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m#     model.fit(parsed_dataset, epochs=50)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-b0860c81d969>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py\u001b[0m in \u001b[0;36mas_dataframe\u001b[1;34m(ds, ds_info)\u001b[0m\n\u001b[0;32m    218\u001b[0m   \u001b[1;31m# Flatten the keys names, specs,... while keeping the feature key definition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m   \u001b[1;31m# order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m   \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m   \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_row_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m   \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStyledDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py\u001b[0m in \u001b[0;36m_make_columns\u001b[1;34m(specs, ds_info)\u001b[0m\n\u001b[0;32m    172\u001b[0m   return [\n\u001b[0;32m    173\u001b[0m       \u001b[0mColumnInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_with_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m   ]\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    172\u001b[0m   return [\n\u001b[0;32m    173\u001b[0m       \u001b[0mColumnInfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_info\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_with_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m   ]\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\applications\\anaconda3\\envs\\nsynth\\lib\\site-packages\\tensorflow_datasets\\core\\as_dataframe.py\u001b[0m in \u001b[0;36mfrom_spec\u001b[1;34m(cls, path, ds_info)\u001b[0m\n\u001b[0;32m     65\u001b[0m   ) -> 'ColumnInfo':\n\u001b[0;32m     66\u001b[0m     \u001b[1;34m\"\"\"Formatter which filters values hard to read and format.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# If ds_info is not provided, no formatting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence item 0: expected str instance, int found"
     ]
    }
   ],
   "source": [
    "def plot_sliding_spectrum(S_abs):\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(S_abs, ref=np.max), y_axis='log', x_axis='time')\n",
    "\n",
    "def run():\n",
    "    DATA_PATH = '../data/nsynth-test.tfrecord'\n",
    "    batch_size = 32\n",
    "    audio_length = 64_000\n",
    "    parsed_dataset = tf.data \\\n",
    "        .TFRecordDataset(DATA_PATH) \\\n",
    "        .map(_parse_function) \\\n",
    "        .batch(batch_size)\n",
    "    \n",
    "    \n",
    "    df = tfds.as_dataframe(parsed_dataset.take(1))\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "#     model = tf.keras.Sequential([\n",
    "#         layers.Input(shape=(audio_length,), batch_size=batch_size),\n",
    "#         layers.Reshape(target_shape=(audio_length, 1)),\n",
    "#         layers.Conv1D(32, 10, activation='relu'),\n",
    "#         layers.MaxPooling1D(2),\n",
    "#         layers.Conv1D(64, 10, activation='relu'),\n",
    "#         layers.MaxPooling1D(256),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(\n",
    "#         optimizer='adam',\n",
    "#         loss='binary_crossentropy',\n",
    "#         metrics=[tf.keras.metrics.Accuracy()]\n",
    "#     )\n",
    "#     model.summary()\n",
    "#     model.fit(parsed_dataset, epochs=50)\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
