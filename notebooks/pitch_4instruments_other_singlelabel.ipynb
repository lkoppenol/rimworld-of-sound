{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7b2d10-c314-4596-9429-cb46b930d5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrument_and_pitch_single_label_model_1621692125\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 122, 1016, 8)      408       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 40, 101, 8)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 36, 92, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 9, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1728)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               885248    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 560)               287280    \n",
      "=================================================================\n",
      "Total params: 1,179,352\n",
      "Trainable params: 1,179,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Found 289205 files belonging to 1 classes.\n",
      "Found 12678 files belonging to 1 classes.\n",
      "Epoch 1/50\n",
      "4519/4519 [==============================] - 855s 189ms/step - loss: 0.5976 - categorical_accuracy: 0.8442 - val_loss: 1.2938 - val_categorical_accuracy: 0.7639\n",
      "Epoch 2/50\n",
      "4519/4519 [==============================] - 851s 188ms/step - loss: 0.5652 - categorical_accuracy: 0.8537 - val_loss: 1.2936 - val_categorical_accuracy: 0.7675\n",
      "Epoch 3/50\n",
      "4519/4519 [==============================] - 816s 180ms/step - loss: 0.5394 - categorical_accuracy: 0.8604 - val_loss: 1.3098 - val_categorical_accuracy: 0.7707\n",
      "Epoch 4/50\n",
      "4519/4519 [==============================] - 815s 180ms/step - loss: 0.5157 - categorical_accuracy: 0.8667 - val_loss: 1.3242 - val_categorical_accuracy: 0.7730\n",
      "INFO:tensorflow:Assets written to: instrument_and_pitch_single_label_model_1621692125\\assets\n"
     ]
    }
   ],
   "source": [
    "## from time import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#ROOT_FOLDER = r\"D/Users/david.isaacspaternostro/broncode/rimworld-of-sound\"\n",
    "ROOT_FOLDER = r\"C:\\Users\\david.isaacspaternos\\broncode\\data\\stft\"\n",
    "LABEL = 'instrument_and_pitch_single_label'\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-5\n",
    "modelsavename = 'instrument_and_pitch_single_label_model_' + str(int(time.time()))\n",
    "print(modelsavename)\n",
    "\n",
    "label_shapes = dict(\n",
    "    instrument=1,\n",
    "    instrument_subtype=33,\n",
    "    pitch=128,\n",
    "    instrument_subtype_and_pitch=5+112,  # 4 instruments, 1 other, 112 pitches\n",
    "    instrument_and_pitch_single_label=5*112,\n",
    ")\n",
    "\n",
    "def get_label(filename, label_type, label_size):\n",
    "    switch = {\n",
    "        \"instrument\": get_instrument_label,\n",
    "        \"instrument_subtype\": get_instrument_subtype_label,\n",
    "        \"pitch\": get_pitch_label,\n",
    "        \"instrument_subtype_and_pitch\": get_multi_label,\n",
    "        \"instrument_and_pitch_single_label\": get_instrument_and_pitch\n",
    "    }\n",
    "    if label_type != \"instrument_and_pitch_single_label\":\n",
    "        sparse_label = switch[label_type](filename)\n",
    "        label = np.zeros((label_size, 1))\n",
    "        label[sparse_label] = 1\n",
    "    else:\n",
    "        label = switch[label_type](filename)\n",
    "    return label\n",
    "\n",
    "def get_instrument_label(filename):\n",
    "    instrument = \"_\".join(filename.split('_')[:-2])\n",
    "    switch = {\n",
    "        'bass': 0,\n",
    "        'brass': 1,\n",
    "        'flute': 2,\n",
    "        'guitar': 3,\n",
    "        'keyboard': 4,\n",
    "        'mallet': 5,\n",
    "        'organ': 6,\n",
    "        'reed': 7,\n",
    "        'string': 8,\n",
    "        'synth_lead': 9,\n",
    "        'vocal': 10,\n",
    "    }\n",
    "    return switch[instrument]\n",
    "\n",
    "def get_instrument_subtype_label(filename):\n",
    "    instrument_label = get_instrument_label(filename)\n",
    "    subtype = filename.split('_')[-2]\n",
    "    switch = {\n",
    "        \"acoustic\": 0,\n",
    "        \"electronic\": 1,\n",
    "        \"synthetic\": 2\n",
    "    }\n",
    "    label = instrument_label * len(switch) + switch[subtype]\n",
    "    return label\n",
    "\n",
    "\n",
    "def get_pitch_label(filename):\n",
    "    label = int(filename.split('-')[1])\n",
    "    return label\n",
    "\n",
    "import time\n",
    "def get_multi_label(filename):\n",
    "    \"\"\" multi label with best recognizable instruments\n",
    "        bass_electronic, vocal acoustic, organ electronic, string acoustic, other_instruments, noise(when added to dataset), pitch \"\"\"\n",
    "    pitch_label = get_pitch_label(filename)\n",
    "    instrument_label = get_instrument_subtype_label(filename)\n",
    "\n",
    "    if instrument_label == 1:\n",
    "        instrument_label = 0      #\"bass_electronic\"\n",
    "    elif instrument_label == 19:\n",
    "        instrument_label = 1      #\"organ_electronic\"\n",
    "    elif instrument_label == 24:\n",
    "        instrument_label = 2      #\"string_acoustic\"\n",
    "    elif instrument_label == 30:\n",
    "        instrument_label = 3      #\"vocal_acoustic\"\n",
    "    else:\n",
    "        instrument_label = 4      #\"other\"\n",
    "\n",
    "    label = np.zeros(5+112) # 5 for instruments, 112 for pitches, lowest = 9, highest is 120 (check vocal synthetic, it has them both)\n",
    "    label[instrument_label] = 1\n",
    "    try:\n",
    "        label[pitch_label+5-9] = 1    # +5 because first 5 are instruments, -9 because 009 is the lowest pitch in the nsynth dataset\n",
    "    except:        \n",
    "        print(filename)\n",
    "        print(label)\n",
    "        time.sleep(10)\n",
    "        \n",
    "    return label  \n",
    "\n",
    "def get_instrument_and_pitch(filename):\n",
    "    pitch_label = get_pitch_label(filename)\n",
    "    instrument_label = get_instrument_subtype_label(filename)\n",
    "\n",
    "    if instrument_label == 1:\n",
    "        instrument_label = 0      #\"bass_electronic\"\n",
    "    elif instrument_label == 19:\n",
    "        instrument_label = 1      #\"organ_electronic\"\n",
    "    elif instrument_label == 24:\n",
    "        instrument_label = 2      #\"string_acoustic\"\n",
    "    elif instrument_label == 30:\n",
    "        instrument_label = 3      #\"vocal_acoustic\"\n",
    "    else:\n",
    "        instrument_label = 4      #\"other\"\n",
    "        \n",
    "    label = np.zeros(5*112)\n",
    "    label[instrument_label*112 + pitch_label-9] = 1\n",
    "#     print(filename)\n",
    "#     print(np.argmax(label))\n",
    "#     time.sleep(10)\n",
    "    \n",
    "    return label\n",
    "\n",
    "def reset(batch_size, label_size):\n",
    "    imgs = np.zeros((batch_size, 126, 1025, 1))\n",
    "    labels = np.zeros((batch_size, label_size))\n",
    "    return imgs, labels\n",
    "\n",
    "def get_dataset(path, label_type, label_size, batch_size):\n",
    "    filenames = [f for r, d, fs in os.walk(path) for f in fs]  # tf uses os.walk to determine file order\n",
    "    labels = [get_label(filename, label_type, label_size) for filename in filenames]\n",
    "    dataset = tf.keras.preprocessing \\\n",
    "        .image_dataset_from_directory(\n",
    "            directory=path,\n",
    "            labels=labels,\n",
    "            color_mode='grayscale',\n",
    "            batch_size=batch_size,\n",
    "            image_size=(126, 1025)\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "# Required folder structure:\n",
    "# ROOT_FOLDER\\train\\anything\\all_your_imgs.png\n",
    "# ROOT_FOLDER\\valid\\anything\\all_your_imgs.png\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(126, 1025, 1)),\n",
    "    keras.layers.Conv2D(8, kernel_size=(5, 10), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(3, 10)),\n",
    "    keras.layers.Conv2D(16, kernel_size=(5, 10), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(3, 10)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(label_shapes[LABEL], activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "train_folder = os.path.join(ROOT_FOLDER, 'train')\n",
    "train_dataset = get_dataset(train_folder, LABEL, label_shapes[LABEL], BATCH_SIZE)\n",
    "valid_folder = os.path.join(ROOT_FOLDER, 'valid')\n",
    "valid_dataset = get_dataset(valid_folder, LABEL, label_shapes[LABEL], BATCH_SIZE)\n",
    "\n",
    "# metric = tf.keras.metrics.Precision(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\n",
    "\n",
    "\n",
    "#model.fit(train_dataset, epochs=EPOCHS, validation_data=valid_dataset, callbacks=[model_checkpoint_callback, early_stop])\n",
    "model = tf.keras.models.load_model('instrument_and_pitch_single_label_model_1621681850')\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"checkpoints/\"+modelsavename,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics='categorical_accuracy')\n",
    "model.fit(train_dataset, epochs=EPOCHS, validation_data=valid_dataset, callbacks=[model_checkpoint_callback, early_stop])\n",
    "\n",
    "model.save(modelsavename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0102d2ae-74ca-45ab-93c5-d2eb9b9b3898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from glob import glob\n",
    "from keras.layers import Input, Dense, Add, BatchNormalization, Conv2D, ReLU, MaxPool2D, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "def relu_bn(inputs):\n",
    "    relu = ReLU()(inputs)\n",
    "    bn = BatchNormalization()(relu)\n",
    "    return bn\n",
    "def residual_block(x, downsample: bool, filters: int,                                        kernel_size: int = 3):\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides= (1 if not downsample else 2),\n",
    "               filters=filters,\n",
    "               padding=\"same\")(x)\n",
    "    y = relu_bn(y)\n",
    "    y = Conv2D(kernel_size=kernel_size,\n",
    "               strides=1,\n",
    "               filters=filters,\n",
    "               padding=\"same\")(y)\n",
    "    if downsample:\n",
    "        x = Conv2D(kernel_size=1,\n",
    "                   strides=2,\n",
    "                   filters=filters,\n",
    "                   padding=\"same\")(x)\n",
    "    out = Add()([x, y])\n",
    "    out = relu_bn(out)\n",
    "    return out\n",
    "def create_res_net():\n",
    "    inputs = Input(shape=(126, 1025, 1))\n",
    "    num_filters = 16\n",
    "    t = BatchNormalization()(inputs)\n",
    "    t = Conv2D(kernel_size=3,\n",
    "               strides=1,\n",
    "               filters=num_filters,\n",
    "               padding=\"same\")(t)\n",
    "    t = relu_bn(t)\n",
    "    num_blocks_list = [2, 5,2]\n",
    "    for i in range(len(num_blocks_list)):\n",
    "        num_blocks = num_blocks_list[i]\n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block(t, downsample=(j==0 and i!=0), filters=num_filters)\n",
    "        num_filters *= 2\n",
    "    t = MaxPool2D(4)(t)\n",
    "    t = Flatten()(t)\n",
    "    outputs = Dense(label_shapes[LABEL], activation='sigmoid')(t)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    metric = tf.keras.metrics.Precision(thresholds=None, top_k=None, class_id=None, name=None, dtype=None)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=metric)\n",
    "    return model\n",
    "\n",
    "\n",
    "    \n",
    "label_shapes = dict(\n",
    "    instrument=1,\n",
    "    instrument_subtype=33,\n",
    "    pitch=128,\n",
    "    instrument_subtype_and_pitch=5+112  # 4 instruments, 1 other, 112 pitches\n",
    ")\n",
    "\n",
    "train_folder = os.path.join(ROOT_FOLDER, 'train')\n",
    "train_dataset = get_dataset(train_folder, LABEL, label_shapes[LABEL], BATCH_SIZE)\n",
    "valid_folder = os.path.join(ROOT_FOLDER, 'valid')\n",
    "valid_dataset = get_dataset(valid_folder, LABEL, label_shapes[LABEL], BATCH_SIZE)\n",
    "model = create_res_net()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"checkpoints/\"+modelsavename,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(train_dataset, epochs=EPOCHS, validation_data=valid_dataset, callbacks=[model_checkpoint_callback, early_stop])\n",
    "model.save(modelsavename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb311b-27c0-4089-b8a4-7ae56be2a675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
