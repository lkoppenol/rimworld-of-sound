{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "2.4.3\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from loguru import logger\n",
    "from dotenv import load_dotenv\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "def _one_hot(tensor: tf.Tensor, size) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    One hot encode a tensor and return it as 1D tensor\n",
    "    :param tensor:\n",
    "    :param size: number of unique values in tensor\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    hot_tensor = tf.one_hot(tensor, size)\n",
    "    shaped_tensor = tf.reshape(hot_tensor, (size,))\n",
    "    return shaped_tensor\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def _parse_function(example_proto):\n",
    "    # Schema\n",
    "    features = {\n",
    "        \"pitch\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "        \"audio\": tf.io.FixedLenFeature([64000], dtype=tf.float32),\n",
    "        \"velocity\": tf.io.FixedLenFeature([1], dtype=tf.int64),\n",
    "        \"instrument_family\": tf.io.FixedLenFeature([1], dtype=tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, features)\n",
    "    data = example['audio']\n",
    "\n",
    "    label_name = 'instrument_family'\n",
    "    label_value_count = 11\n",
    "    # label_name = 'velocity'\n",
    "    # label_value_count = 4\n",
    "    label = _one_hot(example[label_name], label_value_count)\n",
    "    return data, label\n",
    "\n",
    "\n",
    "DATA_PATH = '../data/tfrecords/nsynth-train.tfrecord'\n",
    "DATA_PATH_TEST = '../data/tfrecords/nsynth-valid.tfrecord'\n",
    "\n",
    "batch_size = 64\n",
    "audio_length = 64_000\n",
    "parsed_dataset = tf.data \\\n",
    "    .TFRecordDataset(DATA_PATH) \\\n",
    "    .map(_parse_function) \\\n",
    "    .batch(batch_size)\n",
    "\n",
    "#     test_dataset = tf.data \\\n",
    "#         .TFRecordDataset(DATA_PATH_TEST) \\\n",
    "#         .map(_parse_function) \\\n",
    "#         .batch(batch_size)\n",
    "#     # print(parsed_dataset.shapes )\n",
    "#     model = tf.keras.Sequential([\n",
    "#         layers.Input(shape=(audio_length, )),\n",
    "#         layers.Reshape(target_shape=(audio_length, 1)),\n",
    "#         layers.Conv1D(4, 99, activation='relu' ,kernel_regularizer =tf.keras.regularizers.l2( l=0.01)),\n",
    "#         layers.AveragePooling1D(512),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(11, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(\n",
    "#         optimizer = keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#         loss='categorical_crossentropy',\n",
    "#         metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    "#     )\n",
    "#     model.summary()\n",
    "#     model.fit(parsed_dataset, epochs=10, validation_data=test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea805e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
